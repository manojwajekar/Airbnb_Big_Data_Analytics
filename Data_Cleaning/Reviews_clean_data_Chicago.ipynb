{"cells":[{"cell_type":"code","source":["# Import required packages\n\nimport pyspark.sql.functions as func\nfrom pyspark.sql.functions import split\nfrom pyspark.sql.functions import rand,when\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.sql.functions import col\nimport nltk\nfrom nltk.corpus import stopwords \nnltk.download('stopwords')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Creating dataframe from csv file.\ndata = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"parserLib\", \"UNIVOCITY\").option(\"wholeFile\",\"true\").load(\"/FileStore/tables/th776k3r1500350625365/reviews_chicago.csv\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# To remove listing ID which doesnt start with number.\n\n# TODO: Something doesnt work, Need to check logic.\n\nfrom pyspark.sql.types import BooleanType\nimport re\ndef regex_filter(x):\n    regexs = ['\\d+']\n    \n    if x and x.strip():\n        for r in regexs:\n            if re.match(r, x, re.IGNORECASE):\n                return True\n    return False \n    \n    \nfilter_udf = udf(regex_filter, BooleanType())\n\ndata_filter = data.filter(filter_udf(data.listing_id))"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Create separate dataframe based on the outliers in room pricing, \n# data_filter_pos --> greater than average price\n# data_filter_neg --> lower than average price\ndata_filter_pos = data_filter.where(col(\"listing_id\").isin([\"7921556\",\"18479564\",\"10452642\",\"14859885\",\"6794333\",\"12382366\",\"3629096\",\"16031982\",\"17494091\",\"7330060\"]))\n\ndata_filter_neg = data_filter.where(col(\"listing_id\").isin([\"8459072\",\"1027405\",\"17565878\",\"7124097\",\"15757858\",\"7360828\",\"7327846\",\"14054966\",\"14055052\",  \"17679124\",\"7796730\",\"13186084\"]))\n\n\n# Concat all the reviews for single row\n# Note: This approach is not scalable\ndata_filter_pos_group_by = data_filter_pos.agg(func.concat_ws(\", \",func.collect_list(data_filter_pos.comments))).withColumnRenamed(\"concat_ws(, , collect_list(comments))\",\"comments\")\n\ndata_filter_neg_group_by = data_filter_neg.agg(func.concat_ws(\", \",func.collect_list(data_filter_neg.comments))).withColumnRenamed(\"concat_ws(, , collect_list(comments))\",\"comments\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# function to get the non trivial words from the string\n\nstop=stopwords.words('english') \ndef purify(str_line):\n    str_line =re.sub('[^\\w\\s]+', ' ', str_line) \n    str_line =re.sub('\\s+', ' ', str_line)\n    str_line =re.sub('\\d+', ' ', str_line)\n    str_line = re.sub(\"'\", '', str_line)\n    str_line =re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', str_line)\n    str_line = str_line.lower()\n    str_words = [ j for j in str_line.split() if j not in stop]\n    return str_words"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Clean the string\npos_word_list = str(data_filter_pos_group_by.collect())\npos_word_list = purify(pos_word_list)\n\nneg_word_list = str(data_filter_neg_group_by.collect())\nneg_word_list = purify(neg_word_list)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["pos_words = sc.parallelize(pos_word_list)\nneg_words = sc.parallelize(neg_word_list)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["pos_counts = pos_words.map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b)\nneg_counts = neg_words.map(lambda x: (x,1)).reduceByKey(lambda a,b: a+b)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# Positive words\npos_reversed_map = pos_counts.map(lambda (k,v): (v,k)).sortByKey(False)\npos_original_map = pos_reversed_map.map(lambda (k,v): (v,k))\npos_original_map.take(10)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Negative words\nneg_reversed_map = neg_counts.map(lambda (k,v): (v,k)).sortByKey(False)\nneg_original_map = neg_reversed_map.map(lambda (k,v): (v,k))\nneg_original_map.take(10)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":11}],"metadata":{"name":"Listing_clean_data_Chicago","notebookId":1314831980556667},"nbformat":4,"nbformat_minor":0}
